{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_data():\n",
    "    api_endpoint ='https://api.indeed.com/ads/apisearch'\n",
    "\n",
    "    params = {\n",
    "        'publisher': '448947293830904',\n",
    "        'q': 'SDE',\n",
    "        'l': 'ny',\n",
    "        'jt': 'fulltime',\n",
    "        'limit': 25,\n",
    "        'start': 0 ,\n",
    "        'radius': 100,\n",
    "        'co': 'us',\n",
    "        'userip': '1.2.3.4',\n",
    "        'format': 'json',\n",
    "        'useragent': 'Chrome',\n",
    "        'v': 2\n",
    "    }\n",
    "\n",
    "    rows = []\n",
    "    for i in range(40):\n",
    "        response = requests.get(api_endpoint, params=params)\n",
    "        rows.extend(response.json()['results'])\n",
    "\n",
    "        params['start'] += 25\n",
    "\n",
    "    tb = pd.DataFrame(rows)\n",
    "    tb.to_csv('db.csv')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def get_description(page_url):\n",
    "    \n",
    "    \n",
    "    # enter your codes here\n",
    "    executable_path = '/opt/homebrew/bin/chromedriver'\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path=executable_path)\n",
    "\n",
    "    driver.get(page_url)\n",
    "\n",
    "    description = driver.find_element(By.CSS_SELECTOR, \"div.jobsearch-jobDescriptionText\")\n",
    "    \n",
    "    return description.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dc/wvln0gc568s99mg6ck45xlfc0000gn/T/ipykernel_17315/423266675.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=executable_path)\n"
     ]
    }
   ],
   "source": [
    "db = pd.read_csv(\"db.csv\",header=0,index_col=0)\n",
    "\n",
    "db.drop(columns=\"indeedApply\")\n",
    "db.drop(columns=\"stations\")\n",
    "db.drop(columns=\"refNum\")\n",
    "db.drop(columns=\"onmousedown\")\n",
    "db.drop(columns=\"advertiserId\")\n",
    "\n",
    "description = []\n",
    "\n",
    "for i in range(len(db)):\n",
    "    description.append(get_description(db.url[i]))\n",
    "db['description'] = description\n",
    "\n",
    "db.to_csv('db_with_description.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['c', 'c++', 'c#', 'java', 'javascript', 'python', 'go', 'sql', 'nosql', 'redis', 'html', 'css', 'react', 'angular', 'vue', 'ruby', 'node.js', 'aws', 'django', '.net', 'redux', 'next.js', 'xml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "\n",
    "    li = text.split()\n",
    "\n",
    "    puncs = \"!$%&'()*, -/:;<=>?@[\\]^_`{|}~]\"\n",
    "    li2 = []\n",
    "\n",
    "    for i in range(len(li)):\n",
    "        li2.extend(li[i].split('/'))\n",
    "\n",
    "    vocab = []\n",
    "    for i in range(len(li2)):\n",
    "        vocab.extend(li2[i].split('-'))\n",
    "    \n",
    "    for i in range(len(vocab)):\n",
    "        vocab[i].strip()\n",
    "        vocab[i] = ''.join(ch for ch in vocab[i] if ch not in puncs and ch != '\"')\n",
    "        vocab[i] = vocab[i].lower()\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv(\"db_with_description.csv\",header=0,index_col=0)\n",
    "skills = []\n",
    "for i in range(len(db)):\n",
    "    vocab = tokenize(db.description[i])\n",
    "    requires = []\n",
    "    for word in vocab:\n",
    "        if word in keywords:\n",
    "            requires.append(word)\n",
    "    requires = list(set(requires))\n",
    "    skills.append(requires)\n",
    "db['skills'] = skills\n",
    "db.to_csv('db_with_skills.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv(\"db_with_skills.csv\",header=0,index_col=0)\n",
    "titles = db['jobtitle']\n",
    "processed_titles = []\n",
    "for i in range(len(titles)):\n",
    "    title = tokenize(titles[i])\n",
    "    if 'back' in title or 'backend' in title:\n",
    "        processed_titles.append('back end')\n",
    "    elif 'front' in title or 'frontend' in title:\n",
    "        processed_titles.append('front end')\n",
    "    elif 'software' in title:\n",
    "        processed_titles.append('software developer')\n",
    "    else:\n",
    "        if 'developer' in title:\n",
    "            index = title.index('developer')\n",
    "            processed_titles.append(' '.join(title[0:index + 1]))\n",
    "        elif 'engineer' in title:\n",
    "            index = title.index('engineer')\n",
    "            processed_titles.append(' '.join(title[0:index + 1]))\n",
    "        else:\n",
    "            processed_titles.append(titles[i])\n",
    "db['jobtitle'] = processed_titles\n",
    "db.to_csv('final_db.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('java', 377.0), ('javascript', 335.0), ('python', 291.0), ('sql', 283.0), ('aws', 241.0), ('react', 198.0), ('css', 193.0), ('html', 161.0), ('c++', 136.0), ('angular', 119.0), ('c#', 119.0), ('.net', 92.0), ('c', 92.0), ('go', 89.0), ('nosql', 79.0), ('xml', 56.0), ('node.js', 54.0), ('ruby', 40.0), ('redux', 31.0), ('vue', 30.0), ('django', 26.0), ('redis', 26.0), ('next.js', 6.0)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "db = pd.read_csv(\"final_db.csv\",header=0,index_col=0)\n",
    "\n",
    "dtm = np.zeros((len(db), len(keywords)))\n",
    "for i in range(len(db)):\n",
    "    skills = ast.literal_eval(db.skills[i])\n",
    "    for skill in skills:\n",
    "        j = keywords.index(skill)\n",
    "        dtm[i][j] = 1\n",
    "total = dtm.sum(axis=0)\n",
    "index = np.argsort(total)\n",
    "word = []\n",
    "for i in index:\n",
    "    word.append(keywords[i])\n",
    "value = total[index]\n",
    "dic = dict(zip(word, value))\n",
    "output = sorted(dic.items(), key = lambda item: item[1], reverse=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def read_pdf(file_name = 'resume.pdf'):\n",
    "    with open(file_name, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(file)\n",
    "\n",
    "        text = \"\"\n",
    "        for page in range(pdf_reader.numPages):\n",
    "            page_obj = pdf_reader.getPage(page)\n",
    "            text += page_obj.extractText()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(doc, lemmatized = True, pos_tag = False, remove_stopword = True, lower_case = True, remove_punctuation = True):\n",
    "    docs = nlp(doc)\n",
    "    sents = list(map(lambda s: s.text, docs.sents))\n",
    "    tokenized_sents = list(map(lambda sent: preprocess_token(sent, lemmatized, pos_tag, remove_stopword, lower_case, remove_punctuation), docs.sents))\n",
    "            \n",
    "    return sents, tokenized_sents\n",
    "\n",
    "def preprocess_token(sent, lemmatized, pos_tag, remove_stopword, lower_case, remove_punctuation):\n",
    "    tokenized_sent = []\n",
    "    for token in sent:\n",
    "        text = token.text\n",
    "        if lemmatized:\n",
    "            text = token.lemma_\n",
    "\n",
    "        if remove_stopword:\n",
    "            if token.is_stop:\n",
    "                continue\n",
    "\n",
    "        if remove_punctuation:\n",
    "            if token.is_punct:\n",
    "                continue\n",
    "\n",
    "        if bool(re.search(\"^\\s*$\", token.text)):\n",
    "            continue\n",
    "\n",
    "        if lower_case:\n",
    "            text = text.lower()\n",
    "\n",
    "        if pos_tag:\n",
    "            text = (text, token.pos_)\n",
    "\n",
    "        tokenized_sent.append(text)\n",
    "\n",
    "    return tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHIHAO XIONG shihao.xiong@icloud.com   |  (551) 556 - 4100   |   Jersey City, NJ 07302  GitHub: https://github.com/sxiong5 | Linkedin: https://www.linkedin.com/in/sxiong5 SUMMARY      Seeking a Software Engineer. \n",
      " ['shihao', 'xiong', 'shihao.xiong@icloud.com', '|', '551', '556', '4100', '|', 'jersey', 'city', 'nj', '07302', 'github', 'https://github.com/sxiong5', '|', 'linkedin', 'https://www.linkedin.com/in/sxiong5', 'summary', 'seek', 'software', 'engineer'] \n",
      "\n",
      "\n",
      "Master degree candidate. \n",
      " ['master', 'degree', 'candidate'] \n",
      "\n",
      "\n",
      "A wide range of project experience in web programming. \n",
      " ['wide', 'range', 'project', 'experience', 'web', 'programming'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sents, tokenized_sents = preprocess(read_pdf())\n",
    "\n",
    "for i in range(3):\n",
    "    print(sents[i], \"\\n\",tokenized_sents[i],\"\\n\\n\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "046fafec1ff600f90b822c3ce660687157f5f07f7eaa634e34ca861dd36e448c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
